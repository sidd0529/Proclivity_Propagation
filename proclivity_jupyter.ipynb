{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division #For decimal division.\n",
    "import numpy as np #For use in numerical computation.\n",
    "from matplotlib import pylab as plt #Plotting.\n",
    "import argparse #For commandline input\n",
    "import scipy.io #For loading sparse matrices.\n",
    "import sys\n",
    "import time #Check time of computation.\n",
    "import social_network_learn as snlearn #Custom designed function for train_test_split of nodes.\n",
    "import mixing as mx #Custom designed function for computation of mixing matrices.\n",
    "import feature_scaling as fs #Custom designed function for scaling of mixing matrices.\n",
    "import prone as pr #Custom designed function for computation of prone scores.\n",
    "from unique_elements import custom_unique #Custom designed function for finding appropriate unique array elements.\n",
    "#np.set_printoptions(threshold=np.nan) #Uncomment if you want to print full numpy arrays.\n",
    "from plots import visualize #Custom designed function for visualization of social network array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Notes\n",
    "----------\n",
    "Input parameters.\n",
    "\n",
    "Important parameters\n",
    "----------\n",
    "attributes : dictionary data type (dictionary of attributes)\n",
    "nodes_original : numpy.ndarray data type (nodes-attributes array.)\n",
    "edges : scipy sparse matrix (adjacency matrix with 0s and 1s.)\t\n",
    "edges_array : numpy.ndarray data type (adjacency matrix with 0s and 1s.)\n",
    "keep_missing_values : True/False\n",
    "\t\t\t\t\tTrue -> Include zeroes in node while computing mixing matrices.\n",
    "\t\t\t\t\tFalse -> Ignore zeroes in node while computing mixing matrices.\n",
    "\"\"\"\n",
    "attributes = {0: 'ID', 1: 'Status', 2: 'Gender', 3: 'Major', 4: 'Minor', 5: 'Dorm', 6: 'Year', 7: 'High School'}\n",
    "\n",
    "fname = scipy.io.loadmat('facebook100/American75.mat')\n",
    "\n",
    "nodes_original = fname['local_info']\n",
    "edges = fname['A']\n",
    "edges_array = edges.toarray()\n",
    "\n",
    "attribute_chosen = 5\n",
    "\n",
    "prtype = 'ProNel'\n",
    "\n",
    "keep_missing_values = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partition data into train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_train, nodes_test, label_train, label_test, test_indices = \\\n",
    "        snlearn.train_test_split(chosen_attribute=attribute_chosen, test_ratio=0.03, nodes=nodes_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mixing matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Notes\n",
    "----------\n",
    "Computation of mixing matrices\n",
    "\n",
    "Important parameters\n",
    "----------\t\n",
    "mix_mat : list data type. (stores mixing matrices between different pairs of attributes.)\n",
    "mix_names : list data type. (assign names to mixing matrices between different pairs of attributes.) \n",
    "mix_dict : dictionary data type. (matches names from 'mix_names' with arrays from 'mix_mat'.)\n",
    "\"\"\"\n",
    "mix_mat = [ mx.mixing_matrix(attribute1=i, attribute2=j, nodes=nodes_train, \n",
    "\t                         adjacency=edges_array, keep_missing_values=keep_missing_values) \n",
    "           for i in range(1, len(attributes.keys())) \n",
    "           for j in range(i, len(attributes.keys()))]\n",
    "\n",
    "mix_names = [ 'mix'+str(i)+str(j) \n",
    "             for i in range(1, len(attributes.keys())) \n",
    "             for j in range(i, len(attributes.keys())) ]\n",
    "\n",
    "mix_dict = { mix_names[i] : mix_mat[i] for i in range(len(mix_mat)) }\n",
    "\n",
    "mix_dict.update( { 'mix'+str(j)+str(i) : np.transpose( mix_dict['mix'+str(i)+str(j)] )\n",
    "             for i in range(1, len(attributes.keys())) \n",
    "             for j in range(i+1, len(attributes.keys())) }\t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequency of Attribute Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Important parameters\n",
    "----------\t\n",
    "freq_attribute : list data type (stores frequencies of unique values for different attributes.)\n",
    "freq_names : list data type (assign names to frequency arrays of different attributes.)\n",
    "freq_dict : dictionary data type. (matches names from 'freq_names' with arrays from 'freq_attribute'.)\n",
    "\"\"\"\n",
    "freq_attribute = [ fs.frequency_scaler(nodes=nodes_train, chosen_attribute=i, \n",
    "\t                                    keep_missing_values=keep_missing_values) \n",
    "                    for i in range(1, len(attributes.keys()))]\n",
    "\n",
    "freq_names = [ 'freq_attribute'+str(i) for i in range(1, len(attributes.keys())) ] \n",
    "\n",
    "freq_dict = { freq_names[i] : freq_attribute[i] for i in range(len(freq_attribute)) }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling of mixing matrices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Important parameters\n",
    "----------\t\n",
    "scale_mix_mat : list data type. (stores scaled mixing matrices between different pairs of attributes.)\n",
    "scale_mix_names : list data type. \n",
    "                (assign names to scaled mixing matrices between different pairs of attributes.) \n",
    "scale_mix_dict : dictionary data type. \n",
    "                (matches names from 'scale_mix_names' with arrays from 'scale_mix_mat'.)\n",
    "\"\"\"\n",
    "scale_mix_mat = [ mix_dict['mix'+str(i)+str(j)] / freq_dict['freq_attribute'+str(j)]  \n",
    "           for i in range(1, len(attributes.keys())) \n",
    "           for j in range(1, len(attributes.keys()))]\n",
    "\n",
    "\n",
    "scale_mix_names = [ 'scale_mix'+str(i)+str(j) \n",
    "            for i in range(1, len(attributes.keys())) \n",
    "            for j in range(1, len(attributes.keys())) ]\n",
    "\n",
    "scale_mix_dict = { scale_mix_names[i] : scale_mix_mat[i] for i in range(len(scale_mix_mat)) }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ProNe matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Important parameters\n",
    "----------\t\n",
    "ProNe_Mat : numpy.ndarray data type (stores prone scores.)\n",
    "\"\"\"\n",
    "ProNe_Mat = np.empty( (len(attributes.keys())-1, len(attributes.keys())-1) )\n",
    "for i in range( 1, len(attributes.keys()) ):\n",
    "    for j in range( i, len(attributes.keys()) ):\n",
    "    \tProNe_Mat[i-1, j-1] = pr.choice( Mix=mix_dict['mix'+str(i)+str(j)], Type=prtype )\n",
    "    \tProNe_Mat[j-1, i-1] = ProNe_Mat[i-1, j-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proclivity propagation - prediction / score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for attribute  Dorm  is:  0.6666666666666666 .\n",
      "Confidence in predicted accuracy is:  0.37125944168547026\n",
      "Error in predicted accuracy is:  0.6287405583145298\n",
      "Confidence given by uniform probability distribution is:  0.04 .\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Important parameters\n",
    "----------  \n",
    "score : prediction accuracy.\n",
    "confidence_score : confidence in prediction accuracy.\n",
    "error_score : error in prediction accuracy.\n",
    "\"\"\"\n",
    "score, confidence_score = snlearn.proclivity_score( node_indices=test_indices, chosen_attribute=attribute_chosen, nodes=nodes_train, \\\n",
    "\t   nodes_no_mask=nodes_original, adjacency=edges_array, prone_matrix=ProNe_Mat, attributes_dict=attributes,\\\n",
    "\t   dict_scale_mix=scale_mix_dict, keep_missing_values=keep_missing_values)\n",
    "\n",
    "error_score = 1-confidence_score\n",
    "\n",
    "\n",
    "print \"Accuracy for attribute \", attributes[attribute_chosen], \" is: \", score, \".\"\n",
    "print \"Confidence in predicted accuracy is: \", confidence_score\n",
    "print \"Error in predicted accuracy is: \", error_score\n",
    "print \"Confidence given by uniform probability distribution is: \", \\\n",
    "    1/len( custom_unique(arr=nodes_train[:,attribute_chosen], keep_missing_values=keep_missing_values) ), \".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
